{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input/output\n",
    "============\n",
    "\n",
    "Requirements\n",
    "------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This libraries have to be installed on your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import silx\n",
    "import fabio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDF using FabIO\n",
    "===============\n",
    "\n",
    "For simple access, or fast access to raster format like EDF, MSK, TIFF... we recommand to use fabio `fabio`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading files\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fabio\n",
    "\n",
    "image = fabio.open(\"data/medipix.edf\")\n",
    "\n",
    "# here is the data as a numpy array\n",
    "image.data\n",
    "print(\"Image size:\", image.data.shape)\n",
    "\n",
    "# here is the header as key-value dictionary\n",
    "image.header\n",
    "print(\"Metadata count:\", len(image.header))\n",
    "print(\"Metadata names:\", list(image.header.keys()))\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with it. You can see, it is easy to access to the image data, it is easy to access to simple metadata like *pixel size*. It is more difficult to access to motors or counters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing files\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fabio\n",
    "import numpy\n",
    "\n",
    "image = numpy.random.rand(10, 10)\n",
    "metadata = {'pixel_size': '0.2'}\n",
    "\n",
    "image = fabio.edfimage.edfimage(data=image, header=metadata)\n",
    "image.write('new.edf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert files\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fabio\n",
    "\n",
    "image = fabio.open('data/medipix.edf')\n",
    "image = image.convert('tif')\n",
    "image.save('filename.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls -al filename.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 using h5py\n",
    "===============\n",
    "\n",
    "Read example\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5file = h5py.File('data/test.h5')\n",
    "\n",
    "# print available names at the first level\n",
    "print(\"First children:\", list(h5file['/'].keys()))\n",
    "\n",
    "# reaching a dataset from a sub group\n",
    "dataset = h5file['/diff_map_0000/data/map']\n",
    "\n",
    "# using size and types to not read the full stored data\n",
    "print(\"Dataset:\", dataset.shape, dataset.size, dataset.dtype)\n",
    "\n",
    "# datasets mimics numpy-array\n",
    "# read and apply the operation\n",
    "a = 2 * dataset[0, 5]\n",
    "# copy the data and store it as a numpy-array\n",
    "b = dataset[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write example\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import h5py\n",
    "\n",
    "data = numpy.arange(10000.0)\n",
    "data.shape = 100, 100\n",
    "\n",
    "# write\n",
    "h5file = h5py.File('my_first_one.h5', mode='w')\n",
    "\n",
    "# write data into a dataset from the root\n",
    "h5file['/data1'] = data\n",
    "\n",
    "# write data into a dataset from group1\n",
    "h5file['/group1/data2'] = data\n",
    "\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using silx io\n",
    "============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`silx.io` provides a common API to read spec files, EDF, TIFF, and h5py files. This API is a read-only `h5py`-like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`h5ls` allow you to display the tree contained into an HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import silx.io\n",
    "import silx.io.utils\n",
    "\n",
    "h5file = silx.io.open('data/test.h5')\n",
    "\n",
    "string = silx.io.utils.h5ls(h5file)\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read spec files using silx\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import silx.io\n",
    "data = silx.io.open('data/oleg.dat')\n",
    "\n",
    "# print available scans\n",
    "print(\"First childs:\", data['/'].keys())\n",
    "\n",
    "# print available measurements from the scan 94.1\n",
    "print(\"Containt of measurement:\", data['/94.1/measurement'].keys())\n",
    "\n",
    "# get data from measurement\n",
    "xdata = data['/94.1/measurement/Epoch']\n",
    "ydata = data['/94.1/measurement/bpmi']\n",
    "for row in zip(xdata, ydata):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert spec file to HDF5\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from silx.io.convert import write_to_h5\n",
    "\n",
    "write_to_h5('data/oleg.dat', 'oleg.h5', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls -al oleg.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read EDF file using silx\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import silx.io\n",
    "data = silx.io.open('data/ID16B_diatomee.edf')\n",
    "\n",
    "# Access to the frames\n",
    "frames = data['/scan_0/instrument/detector_0/data']\n",
    "len(frames)  # number of frames\n",
    "frames[0]    # first frame\n",
    "print(\"Number of frames:\", len(frames))\n",
    "print(\"Size of an image:\", frames[0].shape)\n",
    "\n",
    "# Access to motors, monitor, timestanp\n",
    "srot = data['scan_0/instrument/positioners/srot'][...]\n",
    "mon = data['scan_0/measurement/mon'][...]\n",
    "timestamp = data['scan_0/instrument/detector_0/others/time_of_day'][...]\n",
    "for row in zip(timestamp, srot, mon):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read HDF5 using silx\n",
    "--------------------\n",
    "\n",
    "For conveniance, ``silx`` also provides the h5py API for HDF5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import silx.io\n",
    "\n",
    "h5file = silx.io.open('data/test.h5')\n",
    "\n",
    "# print available names at the first level\n",
    "print(\"First children:\", list(h5file['/'].keys()))\n",
    "\n",
    "# reaching a dataset from a sub group\n",
    "dataset = h5file['/diff_map_0000/data/map']\n",
    "\n",
    "# using size and types to not read the full stored data\n",
    "print(\"Dataset:\", dataset.shape, dataset.size, dataset.dtype)\n",
    "\n",
    "# datasets mimics numpy-array\n",
    "# read and apply the operation\n",
    "a = 2 * dataset[0, 5]\n",
    "# copy the data and store it as a numpy-array\n",
    "b = dataset[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "========\n",
    "\n",
    "1. Read the EDF file ``medipix.edf``.\n",
    "2. Process the data\n",
    "   The goal of the processing is to clamp the pixels values to a new range of values ([10%, 90%] of the existing one). To do so:\n",
    "\n",
    "   - Create a mask to detect pixel which are below 10% or above 90% of the current range.\n",
    "   - With the above mask, set the affected pixels to 10% 'low value'.\n",
    "\n",
    "3. Store the source, the mask of changed pixels and the result inside ``process.h5``, as below.\n",
    "\n",
    "   ![Output file structure](images/exercise-result.png)\n",
    "\n",
    "4. Load ``process.h5`` and list the root content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data/medipix.edf\n",
    "# ...\n",
    "\n",
    "# Process the data\n",
    "# ...\n",
    "\n",
    "# Save data into a new file (process.h5)\n",
    "# ...\n",
    "\n",
    "# Load process.h5 and list the root content\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data/medipix.edf\n",
    "import exercicesolution\n",
    "import inspect\n",
    "print(inspect.getsource(exercicesolution.load_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process data\n",
    "import exercicesolution\n",
    "import inspect\n",
    "print(inspect.getsource(exercicesolution.process_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save data\n",
    "import exercicesolution\n",
    "import inspect\n",
    "print(inspect.getsource(exercicesolution.save_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list root\n",
    "import exercicesolution\n",
    "import inspect\n",
    "print(inspect.getsource(exercicesolution.list_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root level:\n",
      "['mask', 'raw', 'result']\n"
     ]
    }
   ],
   "source": [
    "# result\n",
    "import exercicesolution\n",
    "import inspect\n",
    "raw_data, proc_data, mask = exercicesolution.solution(\"data/medipix.edf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imshow(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imshow(proc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
